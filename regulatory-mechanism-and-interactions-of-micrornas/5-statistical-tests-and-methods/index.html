

<!DOCTYPE html>

<html lang="en-US">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">

  

  <link rel="shortcut icon" href="/mitkb/favicon.ico" type="image/x-icon">

  <link rel="stylesheet" href="/mitkb/assets/css/just-the-docs-default.css">

  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-84ETYTKDBN"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-84ETYTKDBN', { 'anonymize_ip': true });
    </script>

  

  
    <script type="text/javascript" src="/mitkb/assets/js/vendor/lunr.min.js"></script>
  
  <script type="text/javascript" src="/mitkb/assets/js/just-the-docs.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>5 Statistical methods | mitkb</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="5 Statistical methods" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Statistical tests and methods" />
<meta property="og:description" content="Statistical tests and methods" />
<link rel="canonical" href="https://ncrnas.github.io/mitkb/regulatory-mechanism-and-interactions-of-micrornas/5-statistical-tests-and-methods/" />
<meta property="og:url" content="https://ncrnas.github.io/mitkb/regulatory-mechanism-and-interactions-of-micrornas/5-statistical-tests-and-methods/" />
<meta property="og:site_name" content="mitkb" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="5 Statistical methods" />
<script type="application/ld+json">
{"description":"Statistical tests and methods","url":"https://ncrnas.github.io/mitkb/regulatory-mechanism-and-interactions-of-micrornas/5-statistical-tests-and-methods/","@type":"WebPage","headline":"5 Statistical methods","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://ncrnas.github.io/mitkb/assets/images/logo.png"}},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  
<meta name="google-site-verification" content="vstkqjcoJe9vQcOOpsCKrxv6WfqZ2SKRNWSv7XoHFeQ" />

<link rel="apple-touch-icon" sizes="180x180" href="/mitkb/assets/images/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/mitkb/assets/images/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/mitkb/assets/images/favicon/favicon-16x16.png">
<link rel="manifest" href="/mitkb/assets/images/favicon/site.webmanifest">
<link rel="mask-icon" href="/mitkb/assets/images/favicon/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#2b5797">
<meta name="theme-color" content="#ffffff">

<!-- for mathjax support -->

  <script type="text/javascript">
  window.MathJax = {
    tex: {
      packages: ['base', 'ams']
    },
    loader: {
      load: ['ui/menu', '[tex]/ams']
    },
    chtml: {
      scale: 0.9
    },
    svg: {
      scale: 0.9
    }
  };
  </script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>



  <script src="https://unpkg.com/vanilla-back-to-top@7.2.1/dist/vanilla-back-to-top.min.js"></script>


<script
  data-cookie-notice='{ "learnMoreLinkEnabled": true, "learnMoreLinkHref": "/mitkb/terms/" }'
  src="https://unpkg.com/cookie-notice@^1/dist/cookie.notice.min.js"
></script>


</head>

<body>
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
    <symbol id="svg-link" viewBox="0 0 24 24">
      <title>Link</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link">
        <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
      </svg>
    </symbol>
    <symbol id="svg-search" viewBox="0 0 24 24">
      <title>Search</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search">
        <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line>
      </svg>
    </symbol>
    <symbol id="svg-menu" viewBox="0 0 24 24">
      <title>Menu</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu">
        <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line>
      </svg>
    </symbol>
    <symbol id="svg-arrow-right" viewBox="0 0 24 24">
      <title>Expand</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right">
        <polyline points="9 18 15 12 9 6"></polyline>
      </svg>
    </symbol>
    <symbol id="svg-doc" viewBox="0 0 24 24">
      <title>Document</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file">
        <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline>
      </svg>
    </symbol>
  </svg>

  <div class="side-bar">
    <div class="site-header">
      <a href="https://ncrnas.github.io/mitkb/" class="site-title lh-tight">
  <div class="site-logo"></div>

</a>
      <a href="#" id="menu-button" class="site-button">
        <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg>
      </a>
    </div>
    <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav">
      
        <ul class="nav-list"><li class="nav-list-item"><a href="https://ncrnas.github.io/mitkb/" class="nav-list-link">Home</a></li><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://ncrnas.github.io/mitkb/regulatory-mechanism-and-interactions-of-micrornas/" class="nav-list-link">Overview</a><ul class="nav-list "><li class="nav-list-item "><a href="https://ncrnas.github.io/mitkb/regulatory-mechanism-and-interactions-of-micrornas/0-front-matter/" class="nav-list-link">0 Front matter</a></li><li class="nav-list-item "><a href="https://ncrnas.github.io/mitkb/regulatory-mechanism-and-interactions-of-micrornas/1-introduction/" class="nav-list-link">1 Introduction</a></li><li class="nav-list-item "><a href="https://ncrnas.github.io/mitkb/regulatory-mechanism-and-interactions-of-micrornas/2-papers-and-their-corresponding-sub-goals/" class="nav-list-link">2 Papers and sub-goals</a></li><li class="nav-list-item "><a href="https://ncrnas.github.io/mitkb/regulatory-mechanism-and-interactions-of-micrornas/3-micrornas-and-other-non-coding-rnas/" class="nav-list-link">3 miRNAs and ncRNAs</a></li><li class="nav-list-item "><a href="https://ncrnas.github.io/mitkb/regulatory-mechanism-and-interactions-of-micrornas/4-high-throughput-biological-experiments/" class="nav-list-link">4 Biological experiments</a></li><li class="nav-list-item  active"><a href="https://ncrnas.github.io/mitkb/regulatory-mechanism-and-interactions-of-micrornas/5-statistical-tests-and-methods/" class="nav-list-link active">5 Statistical methods</a></li><li class="nav-list-item "><a href="https://ncrnas.github.io/mitkb/regulatory-mechanism-and-interactions-of-micrornas/6-machine-learning-theory-and-support-vector-machine/" class="nav-list-link">6 Support vector machine</a></li><li class="nav-list-item "><a href="https://ncrnas.github.io/mitkb/regulatory-mechanism-and-interactions-of-micrornas/7-computational-implementation/" class="nav-list-link">7 Implementation</a></li><li class="nav-list-item "><a href="https://ncrnas.github.io/mitkb/regulatory-mechanism-and-interactions-of-micrornas/8-future-perspectives/" class="nav-list-link">8 Future perspectives</a></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://ncrnas.github.io/mitkb/mirna-target-prediction/" class="nav-list-link">Target prediction</a><ul class="nav-list "><li class="nav-list-item "><a href="https://ncrnas.github.io/mitkb/mirna-target-prediction/micrornas-targeting-and-target-prediction/" class="nav-list-link">Review: miRNA target</a></li><li class="nav-list-item "><a href="https://ncrnas.github.io/mitkb/mirna-target-prediction/two-step-svm-model/" class="nav-list-link">Research: Two-step SVM</a></li><li class="nav-list-item "><a href="https://ncrnas.github.io/mitkb/mirna-target-prediction/two-step-svm-model-supplementary-information/" class="nav-list-link">Supplementary information</a></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://ncrnas.github.io/mitkb/mirna-high-throughput-experiments/" class="nav-list-link">Biological experiments</a><ul class="nav-list "><li class="nav-list-item "><a href="https://ncrnas.github.io/mitkb/mirna-high-throughput-experiments/confounding-factors-in-mirna-experiments/" class="nav-list-link">Research: Confounding</a></li><li class="nav-list-item "><a href="https://ncrnas.github.io/mitkb/mirna-high-throughput-experiments/confounding-factors-in-mirna-experiments-supplementary-information/" class="nav-list-link">Supplementary information</a></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://ncrnas.github.io/mitkb/mirna-and-other-ncrnas/" class="nav-list-link">Other ncRNAs</a><ul class="nav-list "></ul></li><li class="nav-list-item"><a href="https://ncrnas.github.io/mitkb/support-articles/" class="nav-list-link">Support articles</a></li><li class="nav-list-item"><a href="https://ncrnas.github.io/mitkb/contact" class="nav-list-link">Contact us</a></li></ul>

      
    </nav>
    <footer class="site-footer">
      <a href="https://ncrnas.github.io/mitkb/terms">Terms and Privacy Policy</a> <br /><br />
      This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.
    </footer>
  </div>
  <div class="main" id="top">
    <div id="main-header" class="main-header">
      
        <div class="search">
          <div class="search-input-wrap">
            <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search mitkb" aria-label="Search mitkb" autocomplete="off">
            <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label>
          </div>
          <div id="search-results" class="search-results"></div>
        </div>
      
      
      
        <nav aria-label="Auxiliary" class="aux-nav">
          <ul class="aux-nav-list">
            
              <li class="aux-nav-list-item">
                <a href="https://github.com/ncrnas/mitkb" class="site-button"
                  
                >
                  mitkb on github
                </a>
              </li>
            
          </ul>
        </nav>
      
    </div>
    <div id="main-content-wrap" class="main-content-wrap">
      
        <nav aria-label="Breadcrumb" class="breadcrumb-nav">
            <ol class="breadcrumb-nav-list">
              
                <li class="breadcrumb-nav-list-item"><a href="https://ncrnas.github.io/mitkb/regulatory-mechanism-and-interactions-of-micrornas/">Overview</a></li>
              
              <li class="breadcrumb-nav-list-item"><span>5 Statistical methods</span></li>
            </ol>
          </nav>
        
      
      <div id="main-content" class="main-content" role="main">
        
          <h1 class="no_toc" id="5-statistical-tests-and-methods">
        
        
          <a href="#5-statistical-tests-and-methods" class="anchor-heading" aria-labelledby="5-statistical-tests-and-methods"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5 Statistical tests and methods
        
        
      </h1>
    <hr />

<details open="">
  <summary class="text-delta">
    Table of contents
  </summary>
<ol id="markdown-toc">
  <li><a href="#S:5.1" id="markdown-toc-S:5.1">5.1 Parametric statistics: Parameters and Hypothesis testing</a></li>
  <li><a href="#S:5.2" id="markdown-toc-S:5.2">5.2 Non-parametric statistical methods: Wilcoxon rank-sum and Kolmogorov-Smirnov tests</a></li>
  <li><a href="#S:5.3" id="markdown-toc-S:5.3">5.3 Resampling: Bootstrap and Permutation test</a></li>
  <li><a href="#S:5.4" id="markdown-toc-S:5.4">5.4 Multiple comparison tests: Analysis of variance, Bonferroni correction, and False discovery rate</a></li>
  <li><a href="#S:5.5" id="markdown-toc-S:5.5">5.5 Correlation: Pearson’s and Spearman’s correlation coefficients</a></li>
  <li><a href="#S:5.6" id="markdown-toc-S:5.6">5.6 Regression analysis: Multivariate linear regression</a></li>
  <li><a href="#S:5.7" id="markdown-toc-S:5.7">References</a></li>
</ol>

</details><hr />

<p>This chapter describes various statistical methods used in our research.
We used basic statistical methods, such as parametric tests and
correlation, to achieve all three sub-goals of our research, but we used
multiple non-parametric tests only for the second and third sub-goals:
<em><a href="/mitkb/mirna-high-throughput-experiments/">miRNA high-throughput experiments</a></em>,
and <em><a href="/mitkb/mirna-and-other-ncrnas/">miRNA and other ncRNAs</a></em>.
Moreover, we mainly used the resampling approach to achieve the third
sub-goal: <em><a href="/mitkb/mirna-and-other-ncrnas/">miRNA and other ncRNAs</a></em>.</p>
      <h2 id="S:5.1">
        
        
          <a href="#S:5.1" class="anchor-heading" aria-labelledby="S:5.1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5.1 Parametric statistics: Parameters and Hypothesis testing
        
        
      </h2>
    

<p>Statistics tests play important roles in biology to analyze different
kinds of data from biological experiments. Most analyses in biology use
parametric statistics, which can be used only when the data are likely
from a known distribution with parameters. The most commonly used
parametric distribution is the normal distribution, which has two
parameters: \(\mu\) (mean) and \(\sigma^{2}\) (variance). Mean is a measure
of central tendency, whereas variance is a measure of spread. Standard
deviation (\(\sigma\)), which is the square root of variance, is also a
measure of spread. The normal distribution is defined by its probability
density function <a class="citation" href="#Rosner2006">[1]</a> as:</p>

\[\label{eq_norm} f(x) = \dfrac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}x^{2}}. \tag{5.1}\]

<p>The parametric statistics offers various analysis methods, but the most
common method is hypothesis testing. Hypothesis testing is that the null
hypothesis, denoted by <i>H<sub>0</sub></i>, is tested to infer whether the
alternative hypothesis, denoted by <i>H<sub>1</sub></i>, is true or false. The
alternative hypothesis contradicts the null hypothesis in some sense
<a class="citation" href="#Rosner2006">[1]</a>, therefore, if <i>H<sub>0</sub></i> is rejected, <i>H<sub>1</sub></i> is inferred as
“True”, whereas if <i>H<sub>0</sub></i> is accepted, <i>H<sub>1</sub></i> is inferred as “False”.</p>

<p>The p-value is the probability of incorrectly rejecting the null
hypothesis when it is true. For example, the p-value 0.05 means that
there is 5% chance of rejecting the null hypothesis when it is true. Two
significance levels, 0.05 and 0.01, are commonly used as statistically
“significant” or “highly significant”. Moreover, two types of errors may
occur when the null hypothesis is either accepted or rejected (Table
<a href="#T:5.1">5.1</a>). Type I error is the error of rejecting the
null hypothesis when it is true, whereas Type II error is the error of
accepting the null hypothesis when it is false. Type I error is more
important for hypothesis testing because the p-value is equivalent to
the probability of Type I error.</p>

<p><br /></p>
      <h3 id="T:5.1" class="no_toc text-caption">
        
        
          <a href="#T:5.1" class="anchor-heading" aria-labelledby="T:5.1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>Table 5.1</strong>. Four possible outcomes of hypothesis testing.
        
        
      </h3>
    
<p class="fs-2">The table shows the four possible outcomes of hypothesis testing with two error types.</p>

<div class="table-wrapper"><table>
  <thead>
    <tr>
      <th> </th>
      <th><i>H<sub>0</sub></i> is true</th>
      <th><i>H<sub>1</sub></i> is true</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Accept <i>H<sub>0</sub></i></td>
      <td>True Negative</td>
      <td>False Negative <br /> (Type II error)</td>
    </tr>
    <tr>
      <td>Reject <i>H<sub>0</sub></i></td>
      <td>False Positive <br />  (Type I error)</td>
      <td>True Positive</td>
    </tr>
  </tbody>
</table></div><hr />

<p>For analysis of biological data, one of the most common methods for
hypothesis testing is two sample inference. For example, when two
samples, \(x_{1}\) and \(x_{2}\), are normally distributed with equal
variance, the test statistic \(t\) <a class="citation" href="#Rosner2006">[1]</a> is:</p>

\[\label{eq_stu_t} t = \dfrac{\overline{x}_{1}-\overline{x}_{2}}{S\sqrt{\dfrac{1}{n_{1}}+\dfrac{1}{n_{2}}}}, \tag{5.2}\]

<p>where \(S = \sqrt{((n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2})/(n_{1}+n_{2}-2)}\),
\(n_{1}\) and \(n_{2}\) are sample size of \(x_{1}\) and \(x_{2}\), and \(s_{1}\)
and \(s_{2}\) are standard deviation of \(x_{1}\) and \(x_{2}\). The test
statistics enables to determine the sampling distribution under the null
hypothesis, hence the p-value can be calculated from the test
statistics. The calculation method of the test statistics varies
depending on the type of distributions and the properties of the
samples. In the example above, the test statistic \(t\) follows Student’s
t distribution. This test is called two sample Student’s t-test, and it
is used when the variances need to be calculated directly from the
samples.</p>
      <h2 id="S:5.2">
        
        
          <a href="#S:5.2" class="anchor-heading" aria-labelledby="S:5.2"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5.2 Non-parametric statistical methods: Wilcoxon rank-sum and Kolmogorov-Smirnov tests
        
        
      </h2>
    

<p>The parametric statistical methods are valid only when the samples of
interest follow known distributions with parameters. However, the
original distributions of samples are quite often unknown, therefore,
non-parametric statistical methods should be used in these cases.
Non-parametric methods tend to be more robust, and their applicability
is much wider than corresponding parametric methods because they need
fewer assumptions. However, they require a larger sample size to draw
the same conclusion of their corresponding parametric methods because
they usually have less statistical power.</p>

<p>One of the most commonly used non-parametric statistical methods is the
Wilcoxon rank-sum test <a class="citation" href="#Mann1947">[2,3]</a>, which is a two sample
non-parametric test when the samples are independent. It uses a ranking
procedure, in which individual values are ordered and ranked. There are
two approaches, the Mann-Whitney U-test and the normal approximation, to
calculate the test statistics for the Wilcoxon rank-sum test. (i) The
Mann-Whitney U-test <a class="citation" href="#Mann1947">[2]</a> is used to test whether two samples are
drawn from the same distribution. The U value for the U-test is
calculated from the sum of the ranks and the sample size. For example,
the \(U\) value for sample \(x\), denoted as \(U_{x}\), is calculated as
\(U_{x}=R_{x}-n_{x}(n_{x}+1)/2\) where \(R_{x}\) is the sum of the ranks of
\(x\), and \(n_{x}\) is the sample size of \(x\). (ii) The normal
approximation can be used instead of the U-test when the sample size is
large enough (&gt;10) for both samples <a class="citation" href="#Rosner2006">[1]</a>.
The test statistics T for two independent samples, \(x\) and \(y\), is:</p>

\[\label{eq_wc} T = \dfrac{\left[ \left| R_{1} - \dfrac{n_{1}(n_{1}+n_{2}+1)}{2} \right| - \dfrac{1}{2} \right]}{\sqrt{\left( \dfrac{n_{1}n_{2}}{12} \right) (n_{1}+n_{2}+1))}}, \tag{5.3}\]

<p>where \(R_{x}\) is the sum of the ranks of \(x\), and \(n_{x}\) and \(n_{y}\)
are the sample size of \(x\) and \(y\).</p>

<p>The Kolmogorov-Smirnov test (K-S test) is a non-parametric statistical
method that does not use ranking procedures. For instance, the two
sample K-S test is used to infer whether two continuous distributions
differ. The K-S test requires two continuous distribution functions,
\(F(x)\) and \(G(y)\) where the two distributions are defined as
\(X_{1} \ldots X_{m}\) with the size \(m\), and \(Y_{1} \ldots Y_{n}\) with
the size \(n\). In this case, however, both distributions are unknown.
Therefore, empirical distribution functions, \(\hat{F}(x)\) and
\(\hat{G}(y)\), are used instead. An empirical distribution function is a
step function defined as <a class="citation" href="#Kvam2007">[4]</a>:</p>

\[\label{eq_empr} \hat{F}_{n}(x) = \dfrac{1}{n} \sum_{i=1}^{n} I(X_{i} \leq x), \tag{5.4}\]

<p>where \(I(X_{i} \leq x)\) is the indicator function, and is equal to 1 if
\(X_{i} \leq x\) and 0 otherwise. The test statistics \(D\) for the K-S test
<a class="citation" href="#Arnold2005">[5]</a> is:</p>

\[\label{eq_ks} D = \max_x | \hat{F}(x) - \hat{G}(x) |, \tag{5.5}\]

<p>for the hypothesis of this test:</p>

\[\begin{array}{l l l}
      H_{0}: &amp; F(x) = G(x)    &amp; \textrm{for all $x$},  \\
      H_{1}: &amp; F(x) \neq G(x) &amp; \textrm{for some $x$}.  \\
    \end{array}\]

<p><i>H<sub>0</sub></i> is rejected at level \(\alpha\) when D is too
large as in:</p>

\[\label{eq_ks_d} \dfrac{mn}{m+n}D &gt; K_{\alpha}, \tag{5.6}\]

<p>where the critical value of the Kolmogorov distribution, \(K_{\alpha}\), is
found from \(P(K \leq K_{\alpha}) = 1 - \alpha\) <a class="citation" href="#Marsaglia2003">[6]</a>.</p>
      <h2 id="S:5.3">
        
        
          <a href="#S:5.3" class="anchor-heading" aria-labelledby="S:5.3"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5.3 Resampling: Bootstrap and Permutation test
        
        
      </h2>
    

<p>In statistics, resampling methods treat an observed sample as a finite
population <a class="citation" href="#Rizzo2008">[7]</a> and reuse the data of the observed sample.
Resampling approaches have gained popularity in recent years because
sufficient computational power has become available to make enough
random samples to achieve robust statistical analysis <a class="citation" href="#Moore2009">[8]</a>.
Three major applications of resampling are (i) the bootstrapping method
as estimating the characteristics of the sample, (ii) the permutation
test as exchanging labels to perform significant tests, and (iii) the
cross validation approach as validating models by using random subsets.
This section briefly explains two such applications, bootstrapping and
permutation tests. Cross-validation is explained in the next chapter as
an evaluation method for machine learning.</p>

<p>Bootstrapping <a class="citation" href="#Efron1994">[9]</a> is a resampling method that generates random
samples from an observed sample with replacement. Sampling with
replacement means that a randomly drawn observation should put back in
the original sample before drawing the next one <a class="citation" href="#Moore2009">[8]</a>. Bootstrap
is mainly used for estimating population characteristics by collecting
the statistics from many resamples.</p>

<p>Permutation tests are non-parametric procedures based on resampling. The
tests randomly rearrange the data without replacement to create the
sampling distribution of the test statistics under the null hypothesis
<a class="citation" href="#Moore2009">[8]</a>. To illustrate the basic idea of a permutation test,
suppose we have two samples \(x\) with size m and \(y\) with size n. We
first pool all the data points from \(x\) and \(y\), and randomly draw a
point from this pooled set without replacement to make resample controls
with size \(m\) and \(n\). We then iterate this resampling to make a
permutation distribution. The number of resamples depends on a required
statistical power, but 1000 is widely used. The p-value is calculated by
comparing the parameter of the original observation with the permutation
distribution of the parameter <a class="citation" href="#Moore2009">[8]</a>. For instance, if 14 cases of
999 resamples are larger than the parameter of the original sample, the
p-value of one-sided test can be calculated as:</p>

\[\label{eq_pval_perm}
\dfrac{14+1}{999+1} = \dfrac{15}{1000} = 0.015. \tag{5.7}\]

<p>Adding one to both numerator and denominator of Eq. \eqref{eq_pval_perm}
improves the estimate of the p-value.
Moreover, Fisher’s exact test <a class="citation" href="#Fisher1922">[10]</a> is a special case of
permutation test that is used in the analysis of categorical data,
especially for contingency tables with small sample size. For instance,
when the Fisher’s exact test is used for a 2 × 2 table, it
calculates the exact probability by considering all possible values
under the assumption that the margins of the table are fixed
<a class="citation" href="#Moore2009">[8]</a>.</p>
      <h2 id="S:5.4">
        
        
          <a href="#S:5.4" class="anchor-heading" aria-labelledby="S:5.4"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5.4 Multiple comparison tests: Analysis of variance, Bonferroni correction, and False discovery rate
        
        
      </h2>
    

<p>In addition to one and two sample inferences, multisample inference is
also important in many biological analyses. Two major approaches for
multisample inference are the analysis of variance (ANOVA) and multiple
comparison tests.</p>

<p>The ANOVA test concerns the means of several groups, and its hypothesis
is:</p>

\[\begin{array}{l l}
      H_{0}: \textrm{all means are equal},   \\
      H_{1}: \textrm{not all means are equal}.  \\
    \end{array}\]

<p>The F test can be used when each group follows a
normal distribution, and the test statistics \(F\) is:</p>

\[\label{eq_ftest}
F = \dfrac{\textrm{Between Mean Square}}{\textrm{Within Mean Square}}. \tag{5.8}\]

<p>“Between Mean Square” measures the mean among the groups, whereas
“Within Mean Square” measures the mean among individuals within the same
group <a class="citation" href="#Moore2009">[8]</a>.</p>

<p>As for the non-parametric approach, the Kruskal-Wallis test
<a class="citation" href="#Kruskal1952">[11]</a> can be used if some group has no specific distribution.
It is a non-parametric ANOVA test, and it uses ranking procedures as
calculating the sums of the ranks for the groups <a class="citation" href="#Moore2009">[8]</a>.</p>

<p>Multiple comparisons procedures enable to detect the groups that differ
from the others. The most common approach of multiple comparisons is to
simply compare all possible pairs by two sample inference, followed by
p-value adjustment. The p-value adjustment is critical for multiple
comparisons because some differences likely occur just by chance if
there is a large number of groups, and every pair of groups should be
compared <a class="citation" href="#Moore2009">[8]</a>. Many p-value correction methods have been
developed for various cases, and most of them either change the
significance level of the test, \(\alpha\), or consider the false
discovery rate (FDR), which is (False Positive) / (False Positive + True
Negative).</p>

<p>The Bonferroni correction computes an alternative significance level,
\(\alpha^{*}\), defined as <a class="citation" href="#Rosner2006">[1]</a>:</p>

\[\label{eq_bonf} \alpha^{*} = \dfrac{\alpha}{\binom{k}{2}}, \tag{5.9}\]

<p>where \(k\) is the number of groups. For example, there are 45 possible pairs
when \(k = 10\), therefore \(\alpha^{*} = \alpha / 45\). One critical
problem of the Bonferroni correction is to control the overall
experimental-wise type I error rate, hence, no significant pairs may be
found when \(k\) is very large.</p>

<p>The FDR control, or the Benjamini and Hochberg correction
<a class="citation" href="#Benjamini1995">[12]</a>, is to modify p-values without controlling the overall
experimental-wise type I error rate. The FDR aims to control the
proportion of false-positive results <a class="citation" href="#Rosner2006">[1]</a>, therefore, several
significant pairs will be expected to be found.</p>
      <h2 id="S:5.5">
        
        
          <a href="#S:5.5" class="anchor-heading" aria-labelledby="S:5.5"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5.5 Correlation: Pearson’s and Spearman’s correlation coefficients
        
        
      </h2>
    

<p>In statistics, the correlation indicates the statistical relationships
between two or more samples. The correlation coefficient, which ranges
from -1 to 1, represents the degree of correlation. Samples are
positively correlated, negatively correlated, and uncorrelated when the
coefficient is greater than 0, less than 0, and exactly 0, respectively
<a class="citation" href="#Rosner2006">[1]</a>. It is also important to test the significance of
correlation by determining whether an observed correlation coefficient
is significantly different from zero or not.</p>

<p>Pearson’s correlation coefficient, usually denoted as \(r\), indicates the
linear relationships between two samples that follow normal
distribution. For example, two samples, X and Y, have individual
observations represented as \(x_{i}\) and \(y_{i}\) where i = 1, 2, ..., n.
The Pearson’s correlation coefficient, \(r_{xy}\), is <a class="citation" href="#Rosner2006">[1]</a>:</p>

\[\label{eq_pearson} r_{xy} = \dfrac{\sum_{i=1}^{n}(x_{i}-\bar{x})(y_{i}-\bar{y})}{\sqrt{\sum_{i=1}^{n}(x_{i}-\bar{x})^{2}\sum_{i=1}^{n}(y_{i}-\bar{y})^{2}}}. \tag{5.10}\]

<p>This is equivalent to:</p>

\[r_{xy} = \dfrac{s_{xy}}{s_{x}s_{y}} = \dfrac{\textrm{sample covariance between $x$ and $y$}}{(\textrm{sample standard deviation of $x$})(\textrm{sample standard deviation of $y$})}.\]

<p>Spearman’s correlation coefficient, denoted as \(\rho\), is a
non-parametric method. Hence, it can be used when the distributions are
unknown. The calculation of \(\rho\) is similar to that of \(r\), but the
ranks are used instead of the actual observation values <a class="citation" href="#Rosner2006">[1]</a>.</p>
      <h2 id="S:5.6">
        
        
          <a href="#S:5.6" class="anchor-heading" aria-labelledby="S:5.6"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5.6 Regression analysis: Multivariate linear regression
        
        
      </h2>
    

<p>Regression analysis is an important statistical method with biological
data because it identifies the characteristics and relationships among
multiple factors <a class="citation" href="#Schneider2010">[13]</a>. Many types of regression analysis
exist depending on different criteria such as univariate versus
multivariate, or linear versus non-linear, for instance.</p>

<p>Multivariate linear regression can be performed to study the effect of
multiple variables and their linear relationships in the data. The
linear regression model relating \(y\) to \(x_{1}\), ..., \(x_{k}\), is
<a class="citation" href="#Rosner2006">[1]</a>:</p>

\[\label{eq_lreg} y = \alpha + \displaystyle\sum_{j=1}^{k}\beta_{j}x_{j} + e, \tag{5.11}\]

<p>where \(e\) is an error term that is normally distributed with mean 0 and
variance \(\sigma^{2}\). The main goal of the regression analysis is to
minimize \(e\) and estimate the best \(\alpha\) and \(\beta\) to fit this
model.</p>

<p>The goodness of fit for a regression model indicates how well the
observed data fit the predicted model. One of the approaches to measure
the goodness of fit for multiple regression models is to perform
residual analysis <a class="citation" href="#Rosner2006">[1]</a>. Moreover, many procedures of regression
analysis overlap with those of machine learning. Therefore, several
machine learning evaluation methods are also useful to evaluate
regression models. Some of these evaluation methods for machine learning
are explained in the next chapter.</p>
      <h2 id="S:5.7">
        
        
          <a href="#S:5.7" class="anchor-heading" aria-labelledby="S:5.7"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> References
        
        
      </h2>
    
<ol class="bibliography"><li><span id="Rosner2006">Rosner B. Fundamentals of biostatistics. Duxbury Press; 2006.</span>
</li>
<li><span id="Mann1947">Mann HB, Whitney DR. On a test of whether one of two random variables is stochastically larger than the other. The Annals of Mathematical Statistics 1947;18:50–60. <a href="https://doi.org/10.1214/aoms/1177730491">https://doi.org/10.1214/aoms/1177730491.</a></span>
</li>
<li><span id="Wilcoxon1945">Wilcoxon F. Individual comparisons by ranking methods. Biometrics Bulletin 1945;1:80. <a href="https://doi.org/10.2307/3001968">https://doi.org/10.2307/3001968.</a></span>
</li>
<li><span id="Kvam2007">Kvam PH. Nonparametric statistics with applications to science and engineering (Wiley series in probability and statistics. Wiley-Interscience; 2007.</span>
</li>
<li><span id="Arnold2005">Arnold S. Nonparametric statistics. Penn State University; 2005.</span>
</li>
<li><span id="Marsaglia2003">Marsaglia G, Tsang WW, Wang J. Evaluating Kolmogorov’s distribution. Journal of Statistical Software 2003;8:1–4. <a href="https://doi.org/10.18637/jss.v008.i18">https://doi.org/10.18637/jss.v008.i18.</a></span>
</li>
<li><span id="Rizzo2008">Rizzo ML. Statistical computing with R. Chapman and Hall/CRC; 2008.</span>
</li>
<li><span id="Moore2009">Moore DS, McCabe GP, Craig BA. Introduction to the practice of statistics. W.H. Freeman; 2009.</span>
</li>
<li><span id="Efron1994">Efron B, Tibshirani RJ. An introduction to the bootstrap (Chapman &amp; Hall/CRC monographs on statistics &amp; applied probability). First. Chapman and Hall/CRC; 1994.</span>
</li>
<li><span id="Fisher1922">Fisher RA. On the interpretation of χ2 from contingency tables, and the calculation of p. Journal of the Royal Statistical Society 1922;85:87. <a href="https://doi.org/10.2307/2340521">https://doi.org/10.2307/2340521.</a></span>
</li>
<li><span id="Kruskal1952">Kruskal WH, Wallis WA. Use of ranks in one-criterion variance analysis. Journal of the American Statistical Association 1952;47:583–621. <a href="https://doi.org/10.1080/01621459.1952.10483441">https://doi.org/10.1080/01621459.1952.10483441.</a></span>
</li>
<li><span id="Benjamini1995">Benjamini Y, Hochberg Y. Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal Statistical Society: Series B (Methodological) 1995;57:289–300. <a href="https://doi.org/10.1111/j.2517-6161.1995.tb02031.x">https://doi.org/10.1111/j.2517-6161.1995.tb02031.x.</a></span>
</li>
<li><span id="Schneider2010">Schneider A, Hommel G, Blettner M. Linear regression analysis. Deutsches Aerzteblatt Online 2010;107:776–82. <a href="https://doi.org/10.3238/arztebl.2010.0776">https://doi.org/10.3238/arztebl.2010.0776.</a></span>
</li></ol>

        

        

        
          <hr>
          <h2>Leave a comment</h2>
          <div id="disqus_thread"></div>
        

        
        
          <hr>
          <footer>
            
              <p><a href="#top" id="back-to-top">Back to top</a></p>
            

            <p class="text-small text-grey-dk-100 mb-0">Copyright &copy; 2021 Takaya Saito.</p>

            
              <div class="d-flex mt-2">
                
                
              </div>
            
          </footer>
        

      </div>
    </div>

    
      

      <div class="search-overlay"></div>
    
  </div>

  
     <script>addBackToTop({
       id: 'back-to-top-js-button'
     })</script>
  

  
    <script>
        /**
        *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
        *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
        /*
        var disqus_config = function () {
        this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
        };
        */
        (function() { // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');
        s.src = 'https://mitkb.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  

</body>
</html>

